{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Step 1 -- press play if you are on phone{ display-mode: \"form\" }\n",
        "%%html\n",
        "<audio autoplay=\"\" src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" loop controls>"
      ],
      "metadata": {
        "id": "2H92KghtkL1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsUhAZBU-dHc"
      },
      "outputs": [],
      "source": [
        "#@title Step 2 -- press play this to run TavernAI with koboldcpp\n",
        "\n",
        "Model = \"https://huggingface.co/bartowski/magnum-v4-12b-GGUF/resolve/main/magnum-v4-12b-Q5_K_M.gguf\"\n",
        "use_drive_for_chat_backup = True #@param {type:\"boolean\"}\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import shutil\n",
        "import threading\n",
        "import torch\n",
        "import sys\n",
        "import requests\n",
        "if not torch.cuda.is_available():\n",
        "    from IPython.display import display, Markdown\n",
        "    display(Markdown(\"<h1>NO free gpu is avilable for you at the moment</h1>\"))\n",
        "    sys.exit()\n",
        "from google.colab import drive\n",
        "os.chdir(\"/content\")\n",
        "print(\"Chào mừng đến với TavernAI cùng Koboldcpp\")\n",
        "print(\"Sổ tay Colab được viết bởi doctord98 với sự hỗ trợ api bổ sung của vrihatgan\")\n",
        "print(\"Vui lòng đợi trong khi tôi thiết lập mọi thứ cho bạn\")\n",
        "if use_drive_for_chat_backup:\n",
        "  drive.mount('/content/drive')\n",
        "subprocess.call(\"git clone https://github.com/Akimitsujiro/TAI.git\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "src1 = '/content/TavernAI/public/characters'\n",
        "des1 = '/content/drive/MyDrive/TavernAI/characters'\n",
        "src2 = '/content/TavernAI/public/chats'\n",
        "des2 = '/content/drive/MyDrive/TavernAI/chats'\n",
        "Layers = 99\n",
        "ContextSize = 6144\n",
        "subprocess.run(\"wget -O dlfile.tmp https://kcpplinux.concedo.workers.dev && mv dlfile.tmp koboldcpp_linux\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(\"chmod +x ./koboldcpp_linux\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(\"apt install aria2 -y\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "print(\"Tải mô hình\")\n",
        "subprocess.run(f\"aria2c -x 10 -o model.gguf --summary-interval=5 --download-result=default --allow-overwrite=true --file-allocation=none {Model}\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "print(\"Tải thành công...\")\n",
        "print(\"đang tải mô hình...\")\n",
        "command = f\"./koboldcpp_linux model.gguf --usecublas 0 mmq --multiuser --gpulayers {Layers} --contextsize {ContextSize} --quiet\"\n",
        "subprocess.Popen(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "flag_file = \"backup_flag.txt\"\n",
        "if use_drive_for_chat_backup:\n",
        "    if os.path.exists(flag_file):\n",
        "        print(\"Mã đã được thực thi.\")\n",
        "    else:\n",
        "\n",
        "      if not os.path.exists(des1):\n",
        "        os.makedirs(des1)\n",
        "        shutil.copytree(src1, des1, dirs_exist_ok=True)\n",
        "      else:\n",
        "        !rm -rf /content/TavernAI/public/characters/*\n",
        "        shutil.copytree(des1, src1, dirs_exist_ok=True)\n",
        "      if not os.path.exists(des2):\n",
        "        os.makedirs(des2)\n",
        "        shutil.copytree(src2, des2, dirs_exist_ok=True)\n",
        "      else:\n",
        "        !rm -rf /content/TavernAI/public/chats/*\n",
        "        shutil.copytree(des2, src2, dirs_exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "      def backup_thread():\n",
        "        while True:\n",
        "          try:\n",
        "            shutil.copytree(src1, des1, dirs_exist_ok=True)\n",
        "            shutil.copytree(src2, des2, dirs_exist_ok=True)\n",
        "          except Exception as e:\n",
        "            pass\n",
        "\n",
        "          time.sleep(5)\n",
        "\n",
        "      backup_thread = threading.Thread(target=backup_thread)\n",
        "      backup_thread.start()\n",
        "\n",
        "      with open(flag_file, \"w\") as f:\n",
        "        f.write(\"bạn không cần phải chạy lại mã này chỉ cần chạy mã bên dưới nếu liên kết không hoạt động\")\n",
        "\n",
        "subprocess.call(\"npm install -g npm@8.19.3\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "os.chdir(\"/content/TavernAI\")\n",
        "subprocess.call(\"npm install\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "os.chdir('/content/')\n",
        "if not os.path.isfile('cloudflared-linux-amd64'):\n",
        "    os.system('wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64')\n",
        "    os.chmod('cloudflared-linux-amd64', 0o777)\n",
        "\n",
        "os.system('nohup ./cloudflared-linux-amd64 tunnel --url http://127.0.0.1:8000 --metrics 127.0.0.1:31337 > cf.txt 2>&1 &')\n",
        "\n",
        "time.sleep(10)\n",
        "\n",
        "def is_service_up(url, timeout=5):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=timeout)\n",
        "        return response.status_code == 200\n",
        "    except requests.ConnectionError:\n",
        "        return False\n",
        "\n",
        "metrics_url = 'http://127.0.0.1:31337/metrics'\n",
        "if is_service_up(metrics_url):\n",
        "    try:\n",
        "        scrape = requests.get(metrics_url).text\n",
        "        needle = scrape.partition('cloudflared_tunnel_user_hostnames_counts{userHostname=\"')[2].split('\"} 1')[0]\n",
        "\n",
        "        if needle:\n",
        "            with open('cloudflare.log', 'w') as log:\n",
        "                log.write(\"CLOUDFLARE PROVIDES!\" + needle)\n",
        "        print(needle)\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Lỗi khi lấy số liệu: {e}\")\n",
        "else:\n",
        "    print(\"Dịch vụ số liệu không khả dụng.\")\n",
        "\n",
        "os.chdir(\"/content/TavernAI\")\n",
        "!nohup node server.js >/dev/null 2>&1\n"
      ]
    }
  ]
}